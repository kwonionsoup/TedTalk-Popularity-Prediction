{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxUnvjUjaShb"
   },
   "source": [
    "Homework 3:\n",
    "\n",
    "Given a category of genre, you are asked to auto generate some lyrics (at least 4 sentences of lyrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yU1A68KrTDcs",
    "outputId": "64b5206d-bff8-4c3f-91c5-25d3098aaa26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk==3.4\n",
      "  Downloading nltk-3.4.zip (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 18.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\apfle\\anaconda3\\lib\\site-packages (from nltk==3.4) (1.16.0)\n",
      "Collecting singledispatch (from nltk==3.4)\n",
      "  Downloading singledispatch-4.1.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Downloading singledispatch-4.1.0-py2.py3-none-any.whl (6.7 kB)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py): started\n",
      "  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.4-py3-none-any.whl size=1436400 sha256=66d5a3c90e9bc09eff659af2d3454a30c8fc08fe46044ad560d2b7257c5460e4\n",
      "  Stored in directory: c:\\users\\apfle\\appdata\\local\\pip\\cache\\wheels\\db\\96\\da\\0a26fbd3f96b179cc14b813434a0c324a08c0684afdd524c73\n",
      "Successfully built nltk\n",
      "Installing collected packages: singledispatch, nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.7\n",
      "    Uninstalling nltk-3.7:\n",
      "      Successfully uninstalled nltk-3.7\n",
      "Successfully installed nltk-3.4 singledispatch-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U nltk==3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "geyuxEWRcJps",
    "outputId": "43fdafd8-dba9-40d9-d285-4965ea337f0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\apfle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.util import trigrams\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rqWPAe6dedF"
   },
   "source": [
    "**Loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YhHh21YFOkx7"
   },
   "outputs": [],
   "source": [
    "country = []\n",
    "directory = 'Country'\n",
    "for filename in os.scandir(directory):\n",
    "  if filename.is_file():\n",
    "    country.append(filename.path)\n",
    "\n",
    "# converting country to strings\n",
    "country_str = []\n",
    "def read_text_file(file_path):\n",
    "  with open(file_path, 'r') as f:\n",
    "    country_str.append(f.read())\n",
    "\n",
    "for file in country:\n",
    "  file_path = file\n",
    "\n",
    "  read_text_file(file_path)\n",
    "\n",
    "metal = []\n",
    "directory ='Metal'\n",
    "for filename in os.scandir(directory):\n",
    "  if filename.is_file():\n",
    "    metal.append(filename.path)\n",
    "\n",
    "# converting metal to strings\n",
    "metal_str = []\n",
    "def read_text_file(file_path):\n",
    "  with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    metal_str.append(f.read())\n",
    "\n",
    "for file in metal:\n",
    "  file_path = file\n",
    "\n",
    "  read_text_file(file_path)\n",
    "\n",
    "\n",
    "pop = []\n",
    "directory = 'Pop'\n",
    "for filename in os.scandir(directory):\n",
    "  if filename.is_file():\n",
    "    pop.append(filename.path)\n",
    "\n",
    "# converting pop to strings\n",
    "pop_str = []\n",
    "def read_text_file(file_path):\n",
    "  with open(file_path, 'r') as f:\n",
    "    pop_str.append(f.read())\n",
    "\n",
    "for file in pop:\n",
    "  file_path = file\n",
    "\n",
    "  read_text_file(file_path)\n",
    "\n",
    "\n",
    "rock = []\n",
    "directory = 'Rock'\n",
    "for filename in os.scandir(directory):\n",
    "  if filename.is_file():\n",
    "    rock.append(filename.path)\n",
    "\n",
    "# converting rock to strings\n",
    "rock_str = []\n",
    "def read_text_file(file_path):\n",
    "  with open(file_path, 'r') as f:\n",
    "    rock_str.append(f.read())\n",
    "\n",
    "for file in rock:\n",
    "  file_path = file\n",
    "\n",
    "  read_text_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApPW6-yYsEeV"
   },
   "source": [
    "**Pre-process songs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8o8m42vWsGh0"
   },
   "outputs": [],
   "source": [
    "def process(song):\n",
    "\n",
    "  song = song.lower()\n",
    "  song = \"\".join([char for char in song if char not in string.punctuation])\n",
    "  tokenized_song = word_tokenize(song)\n",
    "\n",
    "  return tokenized_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YC_4vFSMsIK0"
   },
   "outputs": [],
   "source": [
    "processed_pop = []\n",
    "for song in pop_str:\n",
    "  processed_pop.append(process(song))\n",
    "\n",
    "processed_country = []\n",
    "for song in country_str:\n",
    "  processed_country.append(process(song))\n",
    "\n",
    "processed_metal = []\n",
    "for song in metal_str:\n",
    "  processed_metal.append(process(song))\n",
    "\n",
    "processed_rock = []\n",
    "for song in rock_str:\n",
    "  processed_rock.append(process(song))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfSSWsVit-UG"
   },
   "source": [
    "**Generating Lyrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fwSTu_GgZBJY"
   },
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ahWabkCSAuo"
   },
   "source": [
    "**Generating Pop Lyrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hyEUfWJxbbAs"
   },
   "outputs": [],
   "source": [
    "data_pop, padded_sents_pop = padded_everygram_pipeline(3, processed_pop)\n",
    "model_pop = MLE(3)\n",
    "model_pop.fit(data_pop, padded_sents_pop)\n",
    "embedding_pop = Word2Vec(processed_pop, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "89eqxlIpnrrP"
   },
   "outputs": [],
   "source": [
    "def generate_pop(seed, num_generated):\n",
    "  sentence = [seed]\n",
    "  for i in range(1, num_generated):\n",
    "    list = embedding_pop.wv.most_similar(seed, topn=50)\n",
    "    score = 0\n",
    "    winner = list[0][0]\n",
    "    for word in list:\n",
    "      if model_pop.score(word[0], seed.split()) > score and word[0] != seed:\n",
    "        winner = word[0]\n",
    "        score = model_pop.score(word[0], seed.split())\n",
    "    sentence.append(winner)\n",
    "    seed = winner\n",
    "  generated_sentence = \" \".join(sentence)\n",
    "  return generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UWfl4BvswHVB"
   },
   "outputs": [],
   "source": [
    "def generate_pop_rev(seed, num_generated):\n",
    "  sentence = [seed]\n",
    "  for i in range(1, num_generated):\n",
    "    list = embedding_pop.wv.most_similar(seed, topn=50)\n",
    "    score = 0\n",
    "    winner = list[0][0]\n",
    "    for word in list:\n",
    "      if (model_pop.score(word[0], seed.split()) > score) and (word[0] not in sentence):\n",
    "        winner = word[0]\n",
    "        score = model_pop.score(word[0], seed.split())\n",
    "    sentence.append(winner)\n",
    "    seed = winner\n",
    "  generated_sentence = \" \".join(sentence)\n",
    "  return generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "YP3EZTsexLNK",
    "outputId": "5e8ada6c-3491-4b1a-e41f-6f3552191c93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'heartbeat blast fair you know that we just a day'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_pop(\"heartbeat\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "IM6rlZjipyuo",
    "outputId": "af6e834d-d665-494b-853f-b79fca6b6d95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'heartbeat blast fair you know that we just a day'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_pop_rev('heartbeat',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMCPGcohuQ7f"
   },
   "source": [
    "**Generating Country Lyrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BhbJdQBMuTze"
   },
   "outputs": [],
   "source": [
    "data_country, padded_sents_country = padded_everygram_pipeline(3, processed_country)\n",
    "model_country = MLE(3)\n",
    "model_country.fit(data_country, padded_sents_country)\n",
    "embedding_country = Word2Vec(processed_country, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "iRtDO00SuggE"
   },
   "outputs": [],
   "source": [
    "def generate_country(seed, num_generated):\n",
    "  sentence = [seed]\n",
    "  for i in range(1, num_generated):\n",
    "    list = embedding_country.wv.most_similar(seed, topn=50)\n",
    "    score = 0\n",
    "    winner = list[0][0]\n",
    "    for word in list:\n",
    "      if model_country.score(word[0], seed.split()) > score and word[0] != seed:\n",
    "        winner = word[0]\n",
    "        score = model_country.score(word[0], seed.split())\n",
    "    sentence.append(winner)\n",
    "    seed = winner\n",
    "  generated_sentence = \" \".join(sentence)\n",
    "  return generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xsp71ajbxFFA"
   },
   "outputs": [],
   "source": [
    "def generate_country_rev(seed, num_generated):\n",
    "  sentence = [seed]\n",
    "  for i in range(1, num_generated):\n",
    "    list = embedding_country.wv.most_similar(seed, topn=50)\n",
    "    score = 0\n",
    "    winner = list[0][0]\n",
    "    for word in list:\n",
    "      if model_country.score(word[0], seed.split()) > score and word[0] not in sentence:\n",
    "        winner = word[0]\n",
    "        score = model_country.score(word[0], seed.split())\n",
    "    sentence.append(winner)\n",
    "    seed = winner\n",
    "  generated_sentence = \" \".join(sentence)\n",
    "  return generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "GUYZTrDrvTjo",
    "outputId": "46c4e67c-832c-4b60-f078-c1f8d8fe6fde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'god dont know the day i dont know the day'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_country('god', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "u8I11q7KxiQU",
    "outputId": "8066218b-6814-408f-d2fc-8ad3bbeb7bc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'god dont know the day i just to me that'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_country_rev('god', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekcNy4_Oun_y"
   },
   "source": [
    "**Generating Metal Lyrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "p-DYQvxNuvEA"
   },
   "outputs": [],
   "source": [
    "data_metal, padded_sents_metal = padded_everygram_pipeline(3, processed_metal)\n",
    "model_metal = MLE(3)\n",
    "model_metal.fit(data_metal, padded_sents_metal)\n",
    "embedding_metal = Word2Vec(processed_metal, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "CkoQ0euEu2hO"
   },
   "outputs": [],
   "source": [
    "def generate_metal(seed, num_generated):\n",
    "  sentence = [seed]\n",
    "  for i in range(1, num_generated):\n",
    "    list = embedding_metal.wv.most_similar(seed, topn=50)\n",
    "    score = 0\n",
    "    winner = list[0][0]\n",
    "    for word in list:\n",
    "      if model_metal.score(word[0], seed.split()) > score and word[0] != seed:\n",
    "        winner = word[0]\n",
    "        score = model_metal.score(word[0], seed.split())\n",
    "    sentence.append(winner)\n",
    "    seed = winner\n",
    "  generated_sentence = \" \".join(sentence)\n",
    "  return generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-BOcpRmjxOut"
   },
   "outputs": [],
   "source": [
    "def generate_metal_rev(seed, num_generated):\n",
    "  sentence = [seed]\n",
    "  for i in range(1, num_generated):\n",
    "    list = embedding_metal.wv.most_similar(seed, topn=50)\n",
    "    score = 0\n",
    "    winner = list[0][0]\n",
    "    for word in list:\n",
    "      if model_metal.score(word[0], seed.split()) > score and word[0] not in sentence:\n",
    "        winner = word[0]\n",
    "        score = model_metal.score(word[0], seed.split())\n",
    "    sentence.append(winner)\n",
    "    seed = winner\n",
    "  generated_sentence = \" \".join(sentence)\n",
    "  return generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "IG9NH0bKvaKI",
    "outputId": "5cb6606a-631b-496a-d2c0-f08667574245"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fire is the one of the one of the one'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_metal('fire',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "rntXFBSsxSrk",
    "outputId": "4dfcf6ec-4d98-419c-b676-f85fcae4c992"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fire is the one of my eyes and i dont'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_metal_rev('fire', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rS7dRxFqu7Gi"
   },
   "source": [
    "**Generating Rock Lyrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "HypW5_1ru-Fb"
   },
   "outputs": [],
   "source": [
    "data_rock, padded_sents_rock = padded_everygram_pipeline(3, processed_rock)\n",
    "model_rock = MLE(3)\n",
    "model_rock.fit(data_rock, padded_sents_rock)\n",
    "embedding_rock = Word2Vec(processed_rock, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "qJxyZ2r3u_-0"
   },
   "outputs": [],
   "source": [
    "def generate_rock(seed, num_generated):\n",
    "  sentence = [seed]\n",
    "  for i in range(1, num_generated):\n",
    "    list = embedding_rock.wv.most_similar(seed, topn=50)\n",
    "    score = 0\n",
    "    winner = list[0][0]\n",
    "    for word in list:\n",
    "      if model_rock.score(word[0], seed.split()) > score and word[0] != seed:\n",
    "        winner = word[0]\n",
    "        score = model_rock.score(word[0], seed.split())\n",
    "    sentence.append(winner)\n",
    "    seed = winner\n",
    "  generated_sentence = \" \".join(sentence)\n",
    "  return generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "M5LPRcSAxWrT"
   },
   "outputs": [],
   "source": [
    "def generate_rock_rev(seed, num_generated):\n",
    "  sentence = [seed]\n",
    "  for i in range(1, num_generated):\n",
    "    list = embedding_rock.wv.most_similar(seed, topn=50)\n",
    "    score = 0\n",
    "    winner = list[0][0]\n",
    "    for word in list:\n",
    "      if model_rock.score(word[0], seed.split()) > score and word[0] not in sentence:\n",
    "        winner = word[0]\n",
    "        score = model_rock.score(word[0], seed.split())\n",
    "    sentence.append(winner)\n",
    "    seed = winner\n",
    "  generated_sentence = \" \".join(sentence)\n",
    "  return generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "HxND7syNvsO9",
    "outputId": "228dddcc-33df-49cc-ebc6-2efa256efe94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'while youre the time to you know that i know'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_rock('while', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "aAfn5prjxZbk",
    "outputId": "bf51ab0a-e773-4ce2-e9e8-27b838b47d72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'while youre the time to you know that i dont'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_rock_rev('while', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
