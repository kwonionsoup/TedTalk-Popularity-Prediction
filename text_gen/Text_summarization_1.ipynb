{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kGIxb72whFvR"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from transformers import pipeline, set_seed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk_VLAbAhWzz",
        "outputId": "59b9565f-4823-4c2e-9541-a67e7d13f920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N8mJooLiC53",
        "outputId": "10528575-6ce6-486f-8d8c-e6025ab8aeb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sumy\n",
            "  Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/97.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt<0.7,>=0.6.1 (from sumy)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting breadability>=0.1.20 (from sumy)\n",
            "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.31.0)\n",
            "Collecting pycountry>=18.2.23 (from sumy)\n",
            "  Downloading pycountry-23.12.11-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.66.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2024.2.2)\n",
            "Building wheels for collected packages: breadability, docopt\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21693 sha256=988532a42e2bce68e39ae7e65ff14cb3aa8886db457b08f3a1afc5f350eef9f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/22/90/b84fcc30e16598db20a0d41340616dbf9b1e82bbcc627b0b33\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=8fc84ea6860a4462a724a5d7c9ab5b70b612bcd9bfd5282681ee96b1caf0ffa8\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built breadability docopt\n",
            "Installing collected packages: docopt, pycountry, breadability, sumy\n",
            "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-23.12.11 sumy-0.11.0\n"
          ]
        }
      ],
      "source": [
        "%pip install sumy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zT2UTVi4hPpv"
      },
      "outputs": [],
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9NkCgIegh9k2"
      },
      "outputs": [],
      "source": [
        "df_org = pd.read_csv(\"/content/drive/MyDrive/CSE6740/dropna_processed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvSQr86NiOat",
        "outputId": "fc86b1e4-851d-4624-c0a1-2b2585229f01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5631\n",
            "4983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-80bd03659bfc>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  summary_and_transcript.drop(drops, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "summary_and_transcript = df_org[['transcript', 'summary']]\n",
        "print(len(summary_and_transcript))\n",
        "summary_and_transcript.dropna()\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "# print(summary_and_transcript.iloc[4, 1])\n",
        "# print(len(summary_and_transcript.iloc[4, 1]))\n",
        "drops = []\n",
        "for i in range(len(summary_and_transcript)):\n",
        "    if isinstance(summary_and_transcript.iloc[i,0],str):\n",
        "        continue\n",
        "    else:\n",
        "        drops.append(i)\n",
        "summary_and_transcript.drop(drops, inplace=True)\n",
        "print(len(summary_and_transcript))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hadkQja0ivPW",
        "outputId": "db2496e8-49ad-4bd2-885d-69a01053f61e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Q7MMdyvxiXEO"
      },
      "outputs": [],
      "source": [
        "def abs_summ(text, num_sentences=15):\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    summarizer = LexRankSummarizer()\n",
        "    summary = summarizer(parser.document, num_sentences)\n",
        "    return \" \".join(str(sentence) for sentence in summary)\n",
        "\n",
        "# Example usage\n",
        "# original_text = summary_and_transcript.iloc[9,0]\n",
        "# print(original_text)\n",
        "# summary = abs_summ(original_text)\n",
        "# print(\"Summary:\", summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn3wCN9dyPNa",
        "outputId": "60307169-99f9-4cb3-bfbc-9549caa7b00d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Tue Apr 16 19:31:27 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0              23W / 300W |      2MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jyM1FkriofF"
      },
      "outputs": [],
      "source": [
        "bart_summaries_1 = pd.DataFrame(columns=['Abstractive', 'Lex-Bart', 'Original'])\n",
        "\n",
        "# Generate summaries for each chunk\n",
        "def final_summ(dataframe):\n",
        "    max_length = 1024\n",
        "    # Load pre-trained model and tokenizer on the specified device\n",
        "    tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "    model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(device)\n",
        "    for i in range(len(dataframe)):\n",
        "        if i ==1:\n",
        "            print(bart_summaries_1)\n",
        "        if i % 100 == 0:\n",
        "            print(i)\n",
        "        if i == 500:\n",
        "            return bart_summaries_1\n",
        "        transcript = summary_and_transcript.iloc[i,0]\n",
        "        original = summary_and_transcript.iloc[i,1]\n",
        "        abstractive_summary = abs_summ(transcript)\n",
        "        ted_talk = [abstractive_summary[i: i+max_length] for i in range(0, len(abstractive_summary), max_length)]\n",
        "        summaries = []\n",
        "        for sentence in ted_talk:\n",
        "            tokenized_chunk = tokenizer.encode(sentence, return_tensors='pt', max_length=max_length, truncation=True).to(device)\n",
        "            # summary_ids = model.generate(tokenized_chunk)\n",
        "            summ = model.generate(tokenized_chunk,num_beams=4, min_length=30, max_length= 200, early_stopping=True)\n",
        "            summary = tokenizer.decode(summ[0], skip_special_tokens=True)\n",
        "            summaries.append(summary)\n",
        "        lex_bart = \" \".join(summaries)\n",
        "        bart_summaries_1.loc[i] = [abstractive_summary, lex_bart, original]\n",
        "    return bart_summaries_1\n",
        "\n",
        "bart_summaries_1 = final_summ(summary_and_transcript)\n",
        "print(len(bart_summaries_1)\n",
        "bart_summaries_1.to_csv(\"/content/drive/MyDrive/CSE6740/bart_summaries.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5-jqJLydRCb",
        "outputId": "15cde9fb-66dc-4efa-97d3-90c9ebd731f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I started thinking about my father and my grandfather and my great-grandfather, and I realized that I had all of these Teds going through my bloodstream -- (Laughter) that I had to consider this \"my element.\" This is what you see. And when I started my blog, it was really this one goal -- I said, \"I am not going to be famous to the world, but I could be famous to people on the Internet.\" And I won it -- I reached all of these people, and I had tens of thousands of people reading about my life every day. Because the joke in this is that this person is not a tyrant, this person is so loving and so sweet that he lets me dress him up and post pictures of him to my blog. These things resonate with us, and, if you think about blogs, you think of high art blogs, the history paintings about, you know, all the biblical stories, and then you have this. And we started with a slide of my Teds, and I had to add this slide, because I knew the minute I showed this, my mom -- my mom will see this, because she does read my blog and she'll say, \"Why wasn't there a picture of me?\" So, I have all the people that I know of. And to think of what we have the ability to do with our blogs; to think about the people that are on those $100 computers, talking about who they are, sharing these personal stories -- this is an amazing thing. So I do something that's very narcissistic -- I am a blogger -- that is an amazing thing for me, because it captures a moment in time every day. But this is amazing, because I can go back to a day -- to April 2005, and say, what was I doing this day? And the last story I really want to tell is this story, because this is probably the one that means the most to me in all of what I'm doing. But the big thing that really influenced us was, her sister wrote to me, and she said -- and she wrote on this blog -- that writing her blog during the last couple of months of her life was probably the best thing that had happened to her, and being able to talk to people and to share what was going on, and being able to write and receive comments. And that was amazing, to be able to know that we had empowered that, and that blogging was something that she felt comfortable doing, and the idea that blogging doesn't have to be scary, that we don't always have to be attack of the blogs, that we can be people who are open, and wanting to help and talk to people. So, this is her legacy, and I think that my call to action to all of you is: think about blogs, think about what they are, think about what you've thought of them, and then actually do it, because it's something that's really going to change our lives.\n",
            "I started thinking about my father and my grandfather and my great-grandfather, and I realized that I had all of these Teds going through my bloodstream. And when I started my blog, it was really this one goal -- I said, \"I am not going to be famous to the world, but I could be famous\" \"I do something that's very narcissistic -- I am a blogger,\" she says. \"This is amazing, because I can go back to a day -- to April 2005, and say, what was I doing this day?\" rite and receive comments. And that was amazing, to be able to know that we had empowered that, and that blogging was something that she felt comfortable doing. So, this is her legacy, and I think that my call to action to all of you is: think about blogs, think about what they are, and then actually do it, because it's really going to change our lives.\n",
            "The founding mother of the blog revolution, Movable Type's Mena Trott, talks about the early days of blogging, when she realized that giving regular people the power to share our lives online is the key to building a friendlier, more connected world.\n"
          ]
        }
      ],
      "source": [
        "print(bart_summaries_1.iloc[0,0])\n",
        "print(bart_summaries_1.iloc[0,1])\n",
        "print(bart_summaries_1.iloc[0,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78krkO-ZxXyE"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "t5_summaries = pd.DataFrame(columns=['Abstractive', 'Lex-t5', 'Original'])\n",
        "\n",
        "def summarize_dataframe_with_t5(dataframe, num_sentences=15):\n",
        "    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "    model = T5ForConditionalGeneration.from_pretrained('t5-base').to(device)\n",
        "    for i in range(len(dataframe)):\n",
        "        if i % 100 == 0:\n",
        "            print(i)\n",
        "        if i == 500:\n",
        "            return t5_summaries\n",
        "        transcript = summary_and_transcript.iloc[i,0]\n",
        "        original = summary_and_transcript.iloc[i,1]\n",
        "        abstractive_summary = abs_summ(transcript, 10)\n",
        "        input_ids = tokenizer.encode(\"summarize: \" + abstractive_summary, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
        "        summary_ids = model.generate(input_ids, num_beams=4, max_length=200, early_stopping=True)\n",
        "        lex_t5 = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "        t5_summaries.loc[i] = [abstractive_summary, lex_t5, original]\n",
        "    return t5_summaries\n",
        "\n",
        "t5_summaries = summarize_dataframe_with_t5(summary_and_transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcVkTLAFlizc",
        "outputId": "c7fda339-a066-4ef4-ccc2-48b1aefe8bf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n"
          ]
        }
      ],
      "source": [
        "print(len(t5_summaries))\n",
        "t5_summaries.to_csv(\"/content/drive/MyDrive/CSE6740/t5_summaries.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGFFcFyo3NLa"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_perplexity(model, tokenizer, text):\n",
        "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "    loss = outputs.loss\n",
        "    return torch.exp(loss).item()\n",
        "\n",
        "def calculate_cosine_similarity(vector1, vector2):\n",
        "    # Reshape vectors for compatibility with cosine_similarity function\n",
        "    vector1 = np.array(vector1).reshape(1, -1)\n",
        "    vector2 = np.array(vector2).reshape(1, -1)\n",
        "    # Calculate cosine similarity\n",
        "    similarity = cosine_similarity(vector1, vector2)\n",
        "    return similarity[0][0]\n",
        "\n",
        "def compute_overall_score(df, model, tokenizer):\n",
        "    perplexity_scores = []\n",
        "    cosine_similarity_scores = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        abstractive_summary = row['Abstractive']\n",
        "        original_text = row['Original']\n",
        "        lex_t5_summary = row['Lex-t5']\n",
        "        # perplexity = calculate_perplexity(model, tokenizer, lex_t5_summary)\n",
        "        # perplexity_scores.append(perplexity)\n",
        "        original_text_embedding = model.get_input_embeddings()(torch.tensor(tokenizer.encode(original_text, return_tensors='pt')).to(device)).mean(dim=1).squeeze().detach().cpu().numpy()\n",
        "        lex_t5_summary_embedding = model.get_input_embeddings()(torch.tensor(tokenizer.encode(lex_t5_summary, return_tensors='pt')).to(device)).mean(dim=1).squeeze().detach().cpu().numpy()\n",
        "        cosine_sim = calculate_cosine_similarity(original_text_embedding, lex_t5_summary_embedding)\n",
        "        cosine_similarity_scores.append(cosine_sim)\n",
        "\n",
        "    # average_perplexity = np.mean(perplexity_scores)\n",
        "    average_cosine_similarity = np.mean(cosine_similarity_scores)\n",
        "\n",
        "    return cosine_similarity_scores, average_cosine_similarity\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base').to(device)\n",
        "overall_t5, avg_t5 = compute_overall_score(t5_summaries, model, tokenizer)\n",
        "print(\"T5 Score:\", overall_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj94ruXZnzWi",
        "outputId": "13f3b227-4878-4a76-b2a7-e622f52bcb7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.7363961, 0.6694827, 0.53489107, 0.50890034, 0.6844784, 0.50570303, 0.59034884, 0.583771, 0.6123754, 0.33063924, 0.67821485, 0.48929858, 0.54496175, 0.6723555, 0.634275, 0.6079096, 0.61761594, 0.4713366, 0.5916115, 0.5218723, 0.5596863, 0.6551231, 0.6471044, 0.45891553, 0.65796185, 0.6483439, 0.64413345, 0.6677161, 0.44425392, 0.6116297, 0.6188425, 0.5416427, 0.45553893, 0.65081084, 0.5765766, 0.4535401, 0.6917925, 0.58510804, 0.5137311, 0.66216946, 0.5966382, 0.5909243, 0.5504982, 0.52516854, 0.5745502, 0.61877716, 0.5828244, 0.66053313, 0.70621085, 0.5933168, 0.60188425, 0.56636024, 0.47541913, 0.7117386, 0.55044866, 0.51752424, 0.6317075, 0.6642766, 0.46108997, 0.6279907, 0.58274716, 0.6758913, 0.6840514, 0.7334981, 0.69077164, 0.7163217, 0.5470681, 0.54765, 0.59228146, 0.46396518, 0.7119931, 0.70878834, 0.69455016, 0.5764084, 0.5992675, 0.65145266, 0.66257524, 0.6205771, 0.37335354, 0.6018231, 0.43644804, 0.6385575, 0.6767786, 0.6006348, 0.60389566, 0.59939384, 0.5211131, 0.5567017, 0.5911606, 0.5938968, 0.61962146, 0.52669394, 0.6175673, 0.61799276, 0.63255215, 0.60056376, 0.6578945, 0.64952874, 0.6949161, 0.7307768, 0.7435399, 0.7230097, 0.33900186, 0.6658591, 0.6472305, 0.5311643, 0.5509362, 0.44591808, 0.42015624, 0.7520895, 0.5099764, 0.45890737, 0.6986565, 0.66391826, 0.65276355, 0.6026404, 0.5975021, 0.5627425, 0.6440567, 0.6417297, 0.5607072, 0.5978433, 0.5209587, 0.5651662, 0.6419375, 0.60020614, 0.6669084, 0.60336185, 0.74813306, 0.66647017, 0.6830954, 0.59800017, 0.6672751, 0.62822545, 0.61518115, 0.6910142, 0.6181216, 0.40565807, 0.6035496, 0.66013, 0.71117127, 0.67539966, 0.59487605, 0.5992179, 0.6225327, 0.72212756, 0.2593636, 0.39537978, 0.6832402, 0.7701365, 0.5437317, 0.69908845, 0.58741695, 0.5532501, 0.60667276, 0.68573564, 0.67485034, 0.5153009, 0.58738774, 0.7423217, 0.64378333, 0.6614702, 0.6558561, 0.54183054, 0.52577776, 0.5629632, 0.4356174, 0.64811516, 0.5481872, 0.62250435, 0.5865589, 0.43966442, 0.5670797, 0.5555552, 0.5874161, 0.751109, 0.715364, 0.5459773, 0.65354246, 0.7265363, 0.67410386, 0.48904598, 0.72917724, 0.5557713, 0.58987, 0.71103054, 0.5629164, 0.7059263, 0.5424775, 0.67393565, 0.6129931, 0.5398785, 0.6133987, 0.6543922, 0.6386602, 0.5668014, 0.583188, 0.6081957, 0.5579492, 0.6376985, 0.6637124, 0.6517372, 0.5642958, 0.5788581, 0.59853995, 0.639951, 0.667604, 0.73037964, 0.6431787, 0.7573099, 0.5824187, 0.72558534, 0.6383817, 0.49822158, 0.6005622, 0.4554501, 0.63566995, 0.6278893, 0.4853332, 0.5770678, 0.58268917, 0.6098335, 0.5392244, 0.5917739, 0.58552754, 0.50703526, 0.70889854, 0.6941445, 0.5058383, 0.66594833, 0.5528141, 0.63175714, 0.58007145, 0.5917357, 0.53298724, 0.57917285, 0.7324009, 0.49669522, 0.38602787, 0.5072067, 0.6384859, 0.6961286, 0.60433495, 0.6085925, 0.6005276, 0.55198663, 0.6430984, 0.52653193, 0.7257539, 0.56645405, 0.6084804, 0.6971456, 0.6666155, 0.6194116, 0.5979211, 0.64969945, 0.55958235, 0.60120296, 0.38505223, 0.6948524, 0.66680044, 0.57286495, 0.69751275, 0.64620477, 0.80568266, 0.62953, 0.6514938, 0.73364204, 0.6482866, 0.6444839, 0.6848984, 0.53089654, 0.59673715, 0.7001355, 0.62653863, 0.55683434, 0.58843285, 0.684945, 0.6594109, 0.6522248, 0.717333, 0.6028281, 0.520337, 0.7040263, 0.6839175, 0.6517544, 0.5729805, 0.56466967, 0.63078374, 0.6413898, 0.6098452, 0.53202844, 0.62295365, 0.60250735, 0.6413571, 0.71987426, 0.72932637, 0.65342927, 0.6656171, 0.53802764, 0.4451645, 0.560375, 0.4060871, 0.6764328, 0.5921804, 0.71940786, 0.6775074, 0.61190253, 0.58003944, 0.52452683, 0.4648301, 0.6658145, 0.64449316, 0.69424427, 0.64197886, 0.68213034, 0.64058733, 0.59256643, 0.68817866, 0.66969156, 0.6011605, 0.5810277, 0.6200465, 0.77735007, 0.386303, 0.52006185, 0.7047345, 0.5919813, 0.68826985, 0.57570165, 0.65724903, 0.5540843, 0.43423003, 0.42670843, 0.64583963, 0.72385126, 0.60626066, 0.65725, 0.5911516, 0.68508536, 0.5852461, 0.59023273, 0.6988995, 0.6550859, 0.6084578, 0.589705, 0.56711155, 0.5761554, 0.48152518, 0.6166893, 0.69733965, 0.64639044, 0.49232668, 0.6487427, 0.60192823, 0.65324473, 0.5370966, 0.71532166, 0.64843667, 0.67121893, 0.6646858, 0.6247996, 0.5993929, 0.7328056, 0.61565197, 0.6955515, 0.6571195, 0.6431361, 0.75568926, 0.77148175, 0.6633691, 0.6530888, 0.7181592, 0.6028799, 0.6962552, 0.7172661, 0.51861906, 0.6466327, 0.5261748, 0.64377046, 0.71625423, 0.6362863, 0.6781174, 0.77261704, 0.7509463, 0.5246469, 0.6732984, 0.61835086, 0.6439464, 0.6653942, 0.5836054, 0.7018986, 0.7023636, 0.65900445, 0.58557415, 0.6897583, 0.57631564, 0.6477079, 0.63019603, 0.53355753, 0.62224585, 0.54980934, 0.5311979, 0.5596613, 0.5933701, 0.6855333, 0.6603893, 0.5816679, 0.6221895, 0.5992404, 0.69268084, 0.6203942, 0.69789696, 0.57556605, 0.67993104, 0.60045594, 0.47625643, 0.700865, 0.677446, 0.54962504, 0.650388, 0.5199603, 0.7045601, 0.58796686, 0.49723572, 0.6050844, 0.6026024, 0.5450703, 0.6238774, 0.59817046, 0.55447924, 0.7087393, 0.6163734, 0.58049476, 0.60865504, 0.66047364, 0.6574998, 0.56757766, 0.47680217, 0.6472322, 0.61696315, 0.4897118, 0.62178844, 0.5181354, 0.68860096, 0.6076932, 0.7039469, 0.72417736, 0.65480447, 0.6331635, 0.6223445, 0.53222525, 0.54190034, 0.65315384, 0.6850486, 0.546538, 0.6444484, 0.6439117, 0.6544837, 0.6164031, 0.61302817, 0.6909329, 0.6192765, 0.6171483, 0.70398307, 0.6900313, 0.570051, 0.7542438, 0.70289844, 0.57353425, 0.60667014, 0.6556016, 0.6979636, 0.6643609, 0.70119226, 0.7242658, 0.8088683, 0.46970683, 0.6825141, 0.66523135, 0.65953344, 0.61294365, 0.7007728, 0.6941769, 0.5662277, 0.63957167, 0.67316014, 0.73272765, 0.70295846, 0.71704066, 0.6651633, 0.68884325, 0.7024443, 0.6666764, 0.6360929, 0.7249489, 0.7082075, 0.6598618, 0.5280134, 0.791832]\n",
            "0.6162201\n"
          ]
        }
      ],
      "source": [
        "print(overall_t5)\n",
        "print(avg_t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXimQPIvipiP"
      },
      "outputs": [],
      "source": [
        "def compute_overall_score(df, model, tokenizer):\n",
        "    perplexity_scores = []\n",
        "    cosine_similarity_scores = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        abstractive_summary = row['Abstractive']\n",
        "        original_text = row['Original']\n",
        "        bart_summary = row['Lex-Bart']\n",
        "        # perplexity = calculate_perplexity(model, tokenizer, bart_summary)\n",
        "        # perplexity_scores.append(perplexity)\n",
        "        original_text_embedding = model.get_input_embeddings()(torch.tensor(tokenizer.encode(original_text, return_tensors='pt')).to(device)).mean(dim=1).squeeze().detach().cpu().numpy()\n",
        "        bart_summary_embedding = model.get_input_embeddings()(torch.tensor(tokenizer.encode(bart_summary, return_tensors='pt')).to(device)).mean(dim=1).squeeze().detach().cpu().numpy()\n",
        "        cosine_sim = calculate_cosine_similarity(original_text_embedding, bart_summary_embedding)\n",
        "        cosine_similarity_scores.append(cosine_sim)\n",
        "    # average_perplexity = np.mean(perplexity_scores)\n",
        "    average_cosine_similarity = np.mean(cosine_similarity_scores)\n",
        "    return cosine_similarity_scores, average_cosine_similarity\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(device)\n",
        "\n",
        "# Compute the overall score\n",
        "overall_score, avg = compute_overall_score(bart_summaries_1, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl06qwaXjzS3",
        "outputId": "3f02d54e-d827-41ad-8b7a-85734ae920da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8657371, 0.8442575, 0.76928145, 0.868539, 0.71671665, 0.7258701, 0.7977317, 0.8380244, 0.791854, 0.6318065, 0.8035615, 0.674251, 0.77203256, 0.8426492, 0.7770408, 0.7728736, 0.726523, 0.75452554, 0.69017494, 0.73740023, 0.7717066, 0.81605273, 0.8176382, 0.72610176, 0.8413888, 0.82535267, 0.8431218, 0.8380389, 0.7422627, 0.7557462, 0.7730943, 0.82554114, 0.67042166, 0.74485075, 0.7788523, 0.72860885, 0.8296911, 0.74877137, 0.7256991, 0.87530327, 0.7284474, 0.8102125, 0.7293006, 0.71124536, 0.6521554, 0.79009295, 0.8123746, 0.7740084, 0.8664996, 0.84985214, 0.73205435, 0.78139573, 0.6875516, 0.87162447, 0.68131495, 0.703416, 0.8598942, 0.8377553, 0.66375816, 0.7917751, 0.8176939, 0.77404416, 0.84254277, 0.87158346, 0.8014062, 0.84652746, 0.7746314, 0.7349194, 0.79600865, 0.6892609, 0.8149552, 0.8466179, 0.87138426, 0.6847086, 0.8136245, 0.8065281, 0.7925178, 0.73966914, 0.5784042, 0.77047527, 0.7429849, 0.8034038, 0.799767, 0.6331129, 0.74131066, 0.8210633, 0.7127347, 0.8299973, 0.81079817, 0.8148043, 0.8554794, 0.79672205, 0.8000457, 0.5674379, 0.74995166, 0.79618436, 0.8575841, 0.7945533, 0.8602654, 0.8459262, 0.790801, 0.8264303, 0.75918794, 0.8316781, 0.8729296, 0.73562217, 0.7522082, 0.7046814, 0.6350068, 0.8856431, 0.68552214, 0.55236495, 0.8089528, 0.8079177, 0.7705642, 0.7697944, 0.66282797, 0.75786465, 0.8866254, 0.72407913, 0.58782065, 0.7978257, 0.7787292, 0.69216603, 0.78601444, 0.80476713, 0.8568568, 0.6996573, 0.89324605, 0.8555015, 0.8092828, 0.72974116, 0.7851794, 0.8237529, 0.76996636, 0.77803564, 0.77878845, 0.7321522, 0.79741263, 0.8232798, 0.8633847, 0.8313684, 0.80579776, 0.78442323, 0.83210516, 0.8462604, 0.40465719, 0.62529767, 0.79999375, 0.8985578, 0.8115113, 0.83509135, 0.8317236, 0.81787884, 0.7415924, 0.7412814, 0.7375581, 0.7939564, 0.69981503, 0.84638727, 0.7972232, 0.83534867, 0.8186521, 0.7334411, 0.70036525, 0.7660057, 0.6826757, 0.7948671, 0.7312666, 0.8428751, 0.7517053, 0.795704, 0.7737855, 0.704588, 0.81979537, 0.85288686, 0.8877897, 0.7444311, 0.82086396, 0.8561305, 0.7292218, 0.6984992, 0.85566103, 0.6901144, 0.83379334, 0.8798312, 0.7965572, 0.77103335, 0.8019424, 0.87559307, 0.79418796, 0.73804915, 0.8331394, 0.7731643, 0.7418934, 0.7481658, 0.68261516, 0.83194184, 0.82796884, 0.8082419, 0.7872212, 0.8255881, 0.80667853, 0.7357795, 0.7676598, 0.8382452, 0.8420359, 0.8333417, 0.85875845, 0.8726429, 0.7750553, 0.815716, 0.88660645, 0.611308, 0.87516487, 0.6178292, 0.8422096, 0.76344717, 0.827101, 0.7463814, 0.7584235, 0.8549137, 0.74123085, 0.7229985, 0.70684946, 0.74061495, 0.81020856, 0.86577845, 0.7099844, 0.796938, 0.7444207, 0.8290483, 0.8136847, 0.8220469, 0.81219196, 0.8316238, 0.86060596, 0.630125, 0.71388245, 0.8250407, 0.82272685, 0.8439499, 0.7186544, 0.7256714, 0.80356526, 0.72715664, 0.85567284, 0.70020497, 0.8260866, 0.81191605, 0.8521816, 0.89167714, 0.87844497, 0.8392676, 0.7216135, 0.80617666, 0.73911446, 0.8575351, 0.6764307, 0.87991774, 0.81992036, 0.73880386, 0.89510477, 0.85079134, 0.8920803, 0.8205487, 0.8135023, 0.88157433, 0.8209825, 0.83841777, 0.81105673, 0.75227565, 0.7773289, 0.82384497, 0.80618525, 0.7809677, 0.79471374, 0.8242804, 0.8353585, 0.860371, 0.88644683, 0.75122464, 0.69950867, 0.86443615, 0.86865264, 0.8210677, 0.80383754, 0.80435145, 0.8091395, 0.79172045, 0.78114724, 0.5976707, 0.86787164, 0.7995433, 0.82875586, 0.8003987, 0.8798564, 0.8438159, 0.8418471, 0.81182706, 0.5942701, 0.85302585, 0.6601314, 0.87058437, 0.7258439, 0.8534656, 0.8564352, 0.7596823, 0.79813206, 0.6129795, 0.43595016, 0.84663117, 0.78952575, 0.80975974, 0.7932983, 0.8753989, 0.85427874, 0.8035513, 0.87779814, 0.8175173, 0.7938134, 0.7350408, 0.83826613, 0.9068168, 0.5772641, 0.818249, 0.7466551, 0.84290195, 0.83112025, 0.8143928, 0.7742375, 0.786669, 0.704934, 0.719247, 0.74667704, 0.8137638, 0.73463047, 0.8490615, 0.7029825, 0.8427626, 0.7719487, 0.80305, 0.7929798, 0.8044398, 0.7561773, 0.80464154, 0.878299, 0.78448486, 0.769948, 0.794402, 0.8696754, 0.80183476, 0.7938491, 0.79374975, 0.82399845, 0.79191655, 0.85389316, 0.86709964, 0.82779634, 0.8375591, 0.80990684, 0.76353633, 0.8525748, 0.87202317, 0.79982424, 0.83102816, 0.86107934, 0.7986895, 0.867594, 0.8672432, 0.7866881, 0.81225324, 0.85436654, 0.8154855, 0.79347396, 0.84327793, 0.807641, 0.82636195, 0.8116145, 0.851869, 0.8815959, 0.8110342, 0.8145753, 0.8668717, 0.89017373, 0.849324, 0.817587, 0.8061149, 0.82532775, 0.8436005, 0.8294201, 0.8323871, 0.8231168, 0.78910923, 0.8895482, 0.7681589, 0.8255791, 0.81140774, 0.8313959, 0.783435, 0.7607211, 0.8142661, 0.7816933, 0.7995978, 0.7464521, 0.8248887, 0.8055719, 0.83418626, 0.83240515, 0.87861294, 0.8052391, 0.7723422, 0.8247738, 0.8079644, 0.83084035, 0.84780186, 0.7625914, 0.86321485, 0.8117298, 0.6696142, 0.7972049, 0.7950627, 0.86124814, 0.8129309, 0.8089504, 0.81743634, 0.8194317, 0.7303592, 0.8354821, 0.8222434, 0.77312434, 0.86649585, 0.7855377, 0.80192065, 0.78653854, 0.82861984, 0.83090967, 0.73082924, 0.74414915, 0.8561381, 0.7921672, 0.82884604, 0.798867, 0.78147125, 0.82332546, 0.85105115, 0.92219126, 0.84143555, 0.7747118, 0.8296024, 0.7932956, 0.7662213, 0.7255157, 0.7975453, 0.83192307, 0.7348005, 0.8142236, 0.76475585, 0.8876623, 0.7883961, 0.82055056, 0.8257971, 0.7797856, 0.8223096, 0.85927117, 0.8761202, 0.74293876, 0.89095294, 0.8323209, 0.7737018, 0.73327714, 0.8231502, 0.78884304, 0.860188, 0.8457384, 0.84929484, 0.8114438, 0.8370653, 0.82096446, 0.8838258, 0.7919301, 0.83202946, 0.87630033, 0.88663316, 0.791743, 0.803117, 0.8466072, 0.83927953, 0.8528518, 0.8135562, 0.8126427, 0.8377357, 0.8489438, 0.80495894, 0.831076, 0.7964558, 0.85286415, 0.80454624, 0.78101796, 0.85001194]\n",
            "0.79468066\n"
          ]
        }
      ],
      "source": [
        "print(overall_score)\n",
        "print(avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tu257e22kEt"
      },
      "outputs": [],
      "source": [
        "%%python -m pip install openai==1.6.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "MFU5CBFeoRgU",
        "outputId": "a40575ca-5df0-48de-cc3e-f76c8d028e40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-355970dd42bf>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_and_transcript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_and_transcript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo-0125\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         messages=[{\"role\": \"system\", \"content\": \"Your goal is to summarize the transcript within 4 sentences.\"},\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 645\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    646\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m         )\n\u001b[0;32m-> 1088\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 853\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    854\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    917\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    959\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    878\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m                 \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_auth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    231\u001b[0m         )\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    197\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    114\u001b[0m                 trace.return_value = (\n\u001b[1;32m    115\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    225\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1288\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "gpt_summaries = pd.DataFrame(columns=['Summary', 'Original'])\n",
        "\n",
        "for i in range(len(summary_and_transcript)):\n",
        "    if i % 100 == 0:\n",
        "        print(i)\n",
        "    if i == 500:\n",
        "        break\n",
        "    transcript = summary_and_transcript.iloc[i,0]\n",
        "    original = summary_and_transcript.iloc[i,1]\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-0125\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"Your goal is to summarize the transcript within 4 sentences.\"},\n",
        "         {\"role\": \"user\", \"content\": transcript}],\n",
        "          temperature=0.7, max_tokens=150, top_p=1)\n",
        "    gpt_summaries.loc[i] = [response.choices[0].message.content, original]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK8i56yX2f_-",
        "outputId": "3285f446-a54b-4a15-b8ef-101f91a4fe10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "496\n",
            "Mena Trott, a blogger, shares her journey of starting a blog in 2001 and the personal stories she shared, including a touching story of a fellow blogger who documented her battle with cancer. She discusses the power of blogging in connecting people and sharing personal experiences, emphasizing the importance of leaving a digital legacy through blogs. Mena reflects on the impact of blogs in shaping personal narratives and creating connections across the world, highlighting the significance of sharing stories through this medium. She encourages the audience to consider the power of blogs and to embrace the platform as a means of personal expression and connection.\n",
            "The founding mother of the blog revolution, Movable Type's Mena Trott, talks about the early days of blogging, when she realized that giving regular people the power to share our lives online is the key to building a friendlier, more connected world.\n"
          ]
        }
      ],
      "source": [
        "print(len(gpt_summaries))\n",
        "print(gpt_summaries.iloc[0,0])\n",
        "print(gpt_summaries.iloc[0,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "MfbU2NF73kn3"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "\n",
        "# Load pre-trained GPT-2 model and tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2Model.from_pretrained('gpt2')\n",
        "\n",
        "# Function to compute cosine similarity\n",
        "def calculate_chatgpt_similarity(df):\n",
        "    similarities = []\n",
        "    # Tokenize the texts\n",
        "    for i in range(len(df)):\n",
        "        inputs1 = tokenizer(df['Summary'][i], return_tensors='pt', padding=False, truncation=True)\n",
        "        inputs2 = tokenizer(df['Original'][i], return_tensors='pt', padding=False, truncation=True)\n",
        "        # Get embeddings for text1\n",
        "        with torch.no_grad():\n",
        "            outputs1 = model(**inputs1)\n",
        "        embeddings1 = outputs1.last_hidden_state.mean(dim=1).to(device).squeeze().detach().cpu().numpy()\n",
        "\n",
        "        # Get embeddings for text2\n",
        "        with torch.no_grad():\n",
        "            outputs2 = model(**inputs2)\n",
        "        embeddings2 = outputs2.last_hidden_state.mean(dim=1).to(device).squeeze().detach().cpu().numpy()\n",
        "        # Calculate cosine similarity\n",
        "        embeddings1 = embeddings1.reshape(1, -1)\n",
        "        embeddings2 = embeddings2.reshape(1, -1)\n",
        "        similarity = cosine_similarity(embeddings1, embeddings2)[0]\n",
        "        similarities.append(similarity)\n",
        "    average_cosine_similarity = np.mean(similarities)\n",
        "    return similarities, average_cosine_similarity\n",
        "\n",
        "\n",
        "# Calculate cosine similarity\n",
        "sim_chatgpt, avg_chatgpt  = calculate_chatgpt_similarity(gpt_summaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daPdcXPy6Y2L",
        "outputId": "cddf803a-8d8b-4178-f884-4a7cf98a37c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([0.99958193], dtype=float32), array([0.99933034], dtype=float32), array([0.9968271], dtype=float32), array([0.99844074], dtype=float32), array([0.9986124], dtype=float32), array([0.999394], dtype=float32), array([0.99881], dtype=float32), array([0.9993689], dtype=float32), array([0.9982764], dtype=float32), array([0.9987984], dtype=float32), array([0.9987745], dtype=float32), array([0.9991476], dtype=float32), array([0.9984833], dtype=float32), array([0.999375], dtype=float32), array([0.99939716], dtype=float32), array([0.9978632], dtype=float32), array([0.9987481], dtype=float32), array([0.9990869], dtype=float32), array([0.99495083], dtype=float32), array([0.9986136], dtype=float32), array([0.99872243], dtype=float32), array([0.9990887], dtype=float32), array([0.9985764], dtype=float32), array([0.99863], dtype=float32), array([0.9991771], dtype=float32), array([0.9963416], dtype=float32), array([0.9982637], dtype=float32), array([0.99554896], dtype=float32), array([0.9987023], dtype=float32), array([0.99901235], dtype=float32), array([0.9990302], dtype=float32), array([0.998262], dtype=float32), array([0.9989076], dtype=float32), array([0.9994345], dtype=float32), array([0.99873173], dtype=float32), array([0.9991003], dtype=float32), array([0.99815625], dtype=float32), array([0.9982565], dtype=float32), array([0.9988374], dtype=float32), array([0.9986952], dtype=float32), array([0.99875027], dtype=float32), array([0.99889827], dtype=float32), array([0.9985036], dtype=float32), array([0.9989177], dtype=float32), array([0.9990988], dtype=float32), array([0.99920964], dtype=float32), array([0.99820745], dtype=float32), array([0.9988524], dtype=float32), array([0.9982956], dtype=float32), array([0.9990983], dtype=float32), array([0.99878174], dtype=float32), array([0.9992455], dtype=float32), array([0.9985485], dtype=float32), array([0.9981953], dtype=float32), array([0.9989587], dtype=float32), array([0.99733716], dtype=float32), array([0.99890375], dtype=float32), array([0.9991708], dtype=float32), array([0.9965838], dtype=float32), array([0.9984523], dtype=float32), array([0.99908864], dtype=float32), array([0.99873257], dtype=float32), array([0.99948215], dtype=float32), array([0.9996983], dtype=float32), array([0.9991598], dtype=float32), array([0.9994599], dtype=float32), array([0.9977932], dtype=float32), array([0.99729276], dtype=float32), array([0.99904054], dtype=float32), array([0.9974385], dtype=float32), array([0.9973614], dtype=float32), array([0.999258], dtype=float32), array([0.9990179], dtype=float32), array([0.9978727], dtype=float32), array([0.9969779], dtype=float32), array([0.9993878], dtype=float32), array([0.99838936], dtype=float32), array([0.998492], dtype=float32), array([0.9985629], dtype=float32), array([0.9992347], dtype=float32), array([0.99749064], dtype=float32), array([0.99938184], dtype=float32), array([0.99881953], dtype=float32), array([0.99942887], dtype=float32), array([0.99889195], dtype=float32), array([0.9994749], dtype=float32), array([0.99857986], dtype=float32), array([0.9986345], dtype=float32), array([0.9963342], dtype=float32), array([0.9987709], dtype=float32), array([0.9979498], dtype=float32), array([0.9995377], dtype=float32), array([0.999177], dtype=float32), array([0.9960321], dtype=float32), array([0.9964204], dtype=float32), array([0.9977966], dtype=float32), array([0.9994859], dtype=float32), array([0.9992318], dtype=float32), array([0.99756944], dtype=float32), array([0.99941754], dtype=float32), array([0.9991942], dtype=float32), array([0.99769604], dtype=float32), array([0.9987345], dtype=float32), array([0.9993538], dtype=float32), array([0.9994323], dtype=float32), array([0.99500895], dtype=float32), array([0.99689186], dtype=float32), array([0.99893516], dtype=float32), array([0.9985701], dtype=float32), array([0.99958664], dtype=float32), array([0.9989806], dtype=float32), array([0.9986615], dtype=float32), array([0.9992335], dtype=float32), array([0.99884486], dtype=float32), array([0.9983885], dtype=float32), array([0.99804664], dtype=float32), array([0.9958218], dtype=float32), array([0.99903023], dtype=float32), array([0.9990523], dtype=float32), array([0.99862254], dtype=float32), array([0.9975457], dtype=float32), array([0.99920064], dtype=float32), array([0.99778575], dtype=float32), array([0.99867064], dtype=float32), array([0.99925363], dtype=float32), array([0.9968044], dtype=float32), array([0.9989343], dtype=float32), array([0.9986635], dtype=float32), array([0.998834], dtype=float32), array([0.99921757], dtype=float32), array([0.99920815], dtype=float32), array([0.9995388], dtype=float32), array([0.9990454], dtype=float32), array([0.99855906], dtype=float32), array([0.9968854], dtype=float32), array([0.9983902], dtype=float32), array([0.99868685], dtype=float32), array([0.9985168], dtype=float32), array([0.99912715], dtype=float32), array([0.99943006], dtype=float32), array([0.99800414], dtype=float32), array([0.9991129], dtype=float32), array([0.9982262], dtype=float32), array([0.99938357], dtype=float32), array([0.99910593], dtype=float32), array([0.9985311], dtype=float32), array([0.9981609], dtype=float32), array([0.998579], dtype=float32), array([0.99883544], dtype=float32), array([0.9995614], dtype=float32), array([0.99844855], dtype=float32), array([0.9991857], dtype=float32), array([0.9995244], dtype=float32), array([0.99686015], dtype=float32), array([0.9987935], dtype=float32), array([0.9983491], dtype=float32), array([0.9985513], dtype=float32), array([0.99939793], dtype=float32), array([0.9988211], dtype=float32), array([0.9976238], dtype=float32), array([0.99819636], dtype=float32), array([0.9993342], dtype=float32), array([0.99883765], dtype=float32), array([0.9972539], dtype=float32), array([0.99227107], dtype=float32), array([0.9980378], dtype=float32), array([0.9991132], dtype=float32), array([0.9985525], dtype=float32), array([0.9976315], dtype=float32), array([0.99872977], dtype=float32), array([0.99672675], dtype=float32), array([0.99807477], dtype=float32), array([0.9977889], dtype=float32), array([0.9971378], dtype=float32), array([0.9986969], dtype=float32), array([0.9984753], dtype=float32), array([0.9993237], dtype=float32), array([0.997962], dtype=float32), array([0.9981097], dtype=float32), array([0.99802494], dtype=float32), array([0.99950856], dtype=float32), array([0.99825114], dtype=float32), array([0.99799037], dtype=float32), array([0.99783206], dtype=float32), array([0.9985031], dtype=float32), array([0.9987247], dtype=float32), array([0.99922186], dtype=float32), array([0.9953617], dtype=float32), array([0.9989873], dtype=float32), array([0.99908704], dtype=float32), array([0.99877], dtype=float32), array([0.99942565], dtype=float32), array([0.99918586], dtype=float32), array([0.9989639], dtype=float32), array([0.99658245], dtype=float32), array([0.99787015], dtype=float32), array([0.9984323], dtype=float32), array([0.9996517], dtype=float32), array([0.9982222], dtype=float32), array([0.99956065], dtype=float32), array([0.99841756], dtype=float32), array([0.999498], dtype=float32), array([0.99861825], dtype=float32), array([0.9987339], dtype=float32), array([0.9976628], dtype=float32), array([0.99921024], dtype=float32), array([0.998926], dtype=float32), array([0.9976328], dtype=float32), array([0.9975802], dtype=float32), array([0.99917656], dtype=float32), array([0.99840534], dtype=float32), array([0.99733955], dtype=float32), array([0.9994652], dtype=float32), array([0.997169], dtype=float32), array([0.9980277], dtype=float32), array([0.9988246], dtype=float32), array([0.9994326], dtype=float32), array([0.9992704], dtype=float32), array([0.9956546], dtype=float32), array([0.9977512], dtype=float32), array([0.9980884], dtype=float32), array([0.9983907], dtype=float32), array([0.9975946], dtype=float32), array([0.99906915], dtype=float32), array([0.9971676], dtype=float32), array([0.9988556], dtype=float32), array([0.99758244], dtype=float32), array([0.99899006], dtype=float32), array([0.9977579], dtype=float32), array([0.999388], dtype=float32), array([0.99922526], dtype=float32), array([0.9995832], dtype=float32), array([0.99941057], dtype=float32), array([0.9974991], dtype=float32), array([0.99922943], dtype=float32), array([0.9992302], dtype=float32), array([0.99912435], dtype=float32), array([0.99480927], dtype=float32), array([0.994685], dtype=float32), array([0.9987714], dtype=float32), array([0.9985973], dtype=float32), array([0.9986578], dtype=float32), array([0.9991293], dtype=float32), array([0.9989608], dtype=float32), array([0.998271], dtype=float32), array([0.9981857], dtype=float32), array([0.99880064], dtype=float32), array([0.9983573], dtype=float32), array([0.998773], dtype=float32), array([0.99920195], dtype=float32), array([0.9966321], dtype=float32), array([0.9994179], dtype=float32), array([0.99905646], dtype=float32), array([0.99907845], dtype=float32), array([0.9983036], dtype=float32), array([0.9987294], dtype=float32), array([0.99879134], dtype=float32), array([0.9987104], dtype=float32), array([0.9993644], dtype=float32), array([0.99774987], dtype=float32), array([0.99909127], dtype=float32), array([0.99919456], dtype=float32), array([0.9989043], dtype=float32), array([0.9995678], dtype=float32), array([0.998537], dtype=float32), array([0.9993136], dtype=float32), array([0.99862784], dtype=float32), array([0.9981523], dtype=float32), array([0.99712795], dtype=float32), array([0.99823886], dtype=float32), array([0.9989836], dtype=float32), array([0.9974905], dtype=float32), array([0.99866897], dtype=float32), array([0.99887055], dtype=float32), array([0.9985471], dtype=float32), array([0.999551], dtype=float32), array([0.9977631], dtype=float32), array([0.9989294], dtype=float32), array([0.9980467], dtype=float32), array([0.99867606], dtype=float32), array([0.9985652], dtype=float32), array([0.9989783], dtype=float32), array([0.9995383], dtype=float32), array([0.9974018], dtype=float32), array([0.9993123], dtype=float32), array([0.9992157], dtype=float32), array([0.99542063], dtype=float32), array([0.999079], dtype=float32), array([0.99918735], dtype=float32), array([0.99899554], dtype=float32), array([0.9996083], dtype=float32), array([0.9980094], dtype=float32), array([0.99886876], dtype=float32), array([0.9980148], dtype=float32), array([0.9989994], dtype=float32), array([0.9988481], dtype=float32), array([0.9991925], dtype=float32), array([0.9989208], dtype=float32), array([0.999072], dtype=float32), array([0.9991503], dtype=float32), array([0.9943535], dtype=float32), array([0.9991107], dtype=float32), array([0.99924034], dtype=float32), array([0.9994538], dtype=float32), array([0.9988668], dtype=float32), array([0.99894905], dtype=float32), array([0.9986519], dtype=float32), array([0.997821], dtype=float32), array([0.99916136], dtype=float32), array([0.99773943], dtype=float32), array([0.9967563], dtype=float32), array([0.9991928], dtype=float32), array([0.9974081], dtype=float32), array([0.9985723], dtype=float32), array([0.9984869], dtype=float32), array([0.99928474], dtype=float32), array([0.9987795], dtype=float32), array([0.99908555], dtype=float32), array([0.9970601], dtype=float32), array([0.9960619], dtype=float32), array([0.9967578], dtype=float32), array([0.99894875], dtype=float32), array([0.99870473], dtype=float32), array([0.9991452], dtype=float32), array([0.9968907], dtype=float32), array([0.998207], dtype=float32), array([0.99873394], dtype=float32), array([0.9982594], dtype=float32), array([0.99921393], dtype=float32), array([0.9966341], dtype=float32), array([0.9995986], dtype=float32), array([0.99897164], dtype=float32), array([0.9993988], dtype=float32), array([0.99721617], dtype=float32), array([0.99912983], dtype=float32), array([0.9987178], dtype=float32), array([0.99964154], dtype=float32), array([0.9989544], dtype=float32), array([0.9988201], dtype=float32), array([0.99844795], dtype=float32), array([0.9986567], dtype=float32), array([0.9977442], dtype=float32), array([0.9982256], dtype=float32), array([0.99875975], dtype=float32), array([0.9954128], dtype=float32), array([0.99927837], dtype=float32), array([0.9987933], dtype=float32), array([0.9988299], dtype=float32), array([0.9970442], dtype=float32), array([0.99899817], dtype=float32), array([0.99837214], dtype=float32), array([0.9990653], dtype=float32), array([0.9985355], dtype=float32), array([0.9992102], dtype=float32), array([0.9989828], dtype=float32), array([0.99766964], dtype=float32), array([0.9985628], dtype=float32), array([0.9986067], dtype=float32), array([0.9988531], dtype=float32), array([0.9985081], dtype=float32), array([0.9987842], dtype=float32), array([0.99889225], dtype=float32), array([0.9992162], dtype=float32), array([0.9987334], dtype=float32), array([0.9991629], dtype=float32), array([0.9995379], dtype=float32), array([0.9990568], dtype=float32), array([0.9977771], dtype=float32), array([0.9977324], dtype=float32), array([0.99964213], dtype=float32), array([0.9988551], dtype=float32), array([0.9991377], dtype=float32), array([0.9988972], dtype=float32), array([0.99917114], dtype=float32), array([0.99906516], dtype=float32), array([0.9978483], dtype=float32), array([0.99781764], dtype=float32), array([0.9979412], dtype=float32), array([0.9990578], dtype=float32), array([0.99862623], dtype=float32), array([0.9994461], dtype=float32), array([0.9997507], dtype=float32), array([0.9977418], dtype=float32), array([0.99858916], dtype=float32), array([0.9982858], dtype=float32), array([0.9992409], dtype=float32), array([0.9984768], dtype=float32), array([0.9976901], dtype=float32), array([0.9994989], dtype=float32), array([0.9993018], dtype=float32), array([0.9988278], dtype=float32), array([0.99836504], dtype=float32), array([0.9993751], dtype=float32), array([0.9995738], dtype=float32), array([0.99945], dtype=float32), array([0.99791086], dtype=float32), array([0.9989231], dtype=float32), array([0.99908733], dtype=float32), array([0.9980697], dtype=float32), array([0.9989768], dtype=float32), array([0.9969385], dtype=float32), array([0.9982423], dtype=float32), array([0.9991941], dtype=float32), array([0.99728435], dtype=float32), array([0.99908185], dtype=float32), array([0.99884874], dtype=float32), array([0.99849534], dtype=float32), array([0.99907404], dtype=float32), array([0.99816954], dtype=float32), array([0.99912876], dtype=float32), array([0.9989049], dtype=float32), array([0.99892294], dtype=float32), array([0.9984591], dtype=float32), array([0.9987441], dtype=float32), array([0.9988089], dtype=float32), array([0.99896765], dtype=float32), array([0.9989354], dtype=float32), array([0.99943584], dtype=float32), array([0.99911237], dtype=float32), array([0.99741864], dtype=float32), array([0.998539], dtype=float32), array([0.99879646], dtype=float32), array([0.9987504], dtype=float32), array([0.99871963], dtype=float32), array([0.9982306], dtype=float32), array([0.99719095], dtype=float32), array([0.9993998], dtype=float32), array([0.9988789], dtype=float32), array([0.9982295], dtype=float32), array([0.9985492], dtype=float32), array([0.9988842], dtype=float32), array([0.99909604], dtype=float32), array([0.999548], dtype=float32), array([0.9985519], dtype=float32), array([0.9989142], dtype=float32), array([0.9995545], dtype=float32), array([0.99856323], dtype=float32), array([0.9973938], dtype=float32), array([0.99359894], dtype=float32), array([0.9989013], dtype=float32), array([0.9988531], dtype=float32), array([0.9985766], dtype=float32), array([0.9994459], dtype=float32), array([0.99961746], dtype=float32), array([0.9983265], dtype=float32), array([0.99861354], dtype=float32), array([0.99936104], dtype=float32), array([0.9990567], dtype=float32), array([0.99626064], dtype=float32), array([0.99913365], dtype=float32), array([0.9988433], dtype=float32), array([0.9984935], dtype=float32), array([0.99705726], dtype=float32), array([0.99839425], dtype=float32), array([0.99937147], dtype=float32), array([0.99821377], dtype=float32), array([0.99824965], dtype=float32), array([0.9993327], dtype=float32), array([0.99748605], dtype=float32), array([0.9989302], dtype=float32), array([0.99899805], dtype=float32), array([0.99940985], dtype=float32), array([0.99844587], dtype=float32), array([0.99877155], dtype=float32), array([0.99914503], dtype=float32), array([0.99945176], dtype=float32), array([0.99795324], dtype=float32), array([0.9992765], dtype=float32), array([0.9991435], dtype=float32), array([0.9993501], dtype=float32), array([0.99872786], dtype=float32), array([0.9987397], dtype=float32), array([0.99932796], dtype=float32), array([0.99870193], dtype=float32), array([0.9949562], dtype=float32), array([0.99790084], dtype=float32), array([0.99931884], dtype=float32), array([0.9988905], dtype=float32), array([0.9985405], dtype=float32), array([0.9993845], dtype=float32), array([0.9971172], dtype=float32), array([0.99965036], dtype=float32), array([0.9987639], dtype=float32), array([0.99970335], dtype=float32), array([0.9983938], dtype=float32), array([0.9970744], dtype=float32), array([0.9989993], dtype=float32), array([0.9993647], dtype=float32), array([0.99724644], dtype=float32), array([0.9988476], dtype=float32), array([0.9978692], dtype=float32), array([0.9978069], dtype=float32), array([0.99899566], dtype=float32), array([0.9993832], dtype=float32), array([0.99904126], dtype=float32), array([0.9991363], dtype=float32)]\n",
            "0.9985162\n"
          ]
        }
      ],
      "source": [
        "print(sim_chatgpt)\n",
        "print(avg_chatgpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKj-1-HFBlKU",
        "outputId": "ffc91f86-8fea-4f09-a86a-399fd91423d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mena Trott, a blogger, shares her journey of starting a blog in 2001 and the personal stories she shared, including a touching story of a fellow blogger who documented her battle with cancer. She discusses the power of blogging in connecting people and sharing personal experiences, emphasizing the importance of leaving a digital legacy through blogs. Mena reflects on the impact of blogs in shaping personal narratives and creating connections across the world, highlighting the significance of sharing stories through this medium. She encourages the audience to consider the power of blogs and to embrace the platform as a means of personal expression and connection.\n",
            "The founding mother of the blog revolution, Movable Type's Mena Trott, talks about the early days of blogging, when she realized that giving regular people the power to share our lives online is the key to building a friendlier, more connected world.\n"
          ]
        }
      ],
      "source": [
        "print(gpt_summaries.iloc[0,0])\n",
        "print(gpt_summaries.iloc[0,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "bjIh1bv8DrxN"
      },
      "outputs": [],
      "source": [
        "gpt_summaries.to_csv(\"/content/drive/MyDrive/CSE6740/gpt_summaries.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EIfVodtEGe8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
